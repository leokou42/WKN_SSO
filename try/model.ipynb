{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.model import Laplace_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "/Users/yentsokuo/git_repo/WKN_SSO/try/../src/model.py:41: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1009.)\n",
      "  return F.conv1d(waveforms, self.filters, stride=1, padding='same', dilation=1, bias=None, groups=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2560])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 2560)\n",
    "\n",
    "WKN = Laplace_fast(32,64)\n",
    "WKN_input = WKN(input)\n",
    "WKN_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2560])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = input.squeeze()\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2560])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 2560)\n",
    "\n",
    "c0 = nn.Conv1d(1, 32, kernel_size=32, padding='same')\n",
    "z = c0(input)\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1280])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pool of size=3, stride=2\n",
    "m1 = nn.MaxPool1d(2, stride=2)\n",
    "a = m1(z)\n",
    "\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1280])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = nn.Conv1d(32, 16, kernel_size=32, padding='same')\n",
    "b = c1(a)\n",
    "\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 640])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = nn.MaxPool1d(2, stride=2)\n",
    "c = m1(b)\n",
    "\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 640])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = nn.Conv1d(16, 32, kernel_size=32, padding='same')\n",
    "d = c2(c)\n",
    "\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 320])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = nn.MaxPool1d(2, stride=2)\n",
    "e = m3(d)\n",
    "\n",
    "e.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 16])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "e = e.view(320, 32)\n",
    "BiGRU = nn.GRU(input_size=32, hidden_size=8, num_layers=1, bidirectional=True)\n",
    "output, hidden = BiGRU(e)\n",
    "\n",
    "# 訪問最後一個時間步的隱藏狀態的形狀\n",
    "print(output.shape)\n",
    "# 或者訪問整個序列的隱藏狀態的形狀\n",
    "print(hidden.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5120])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = nn.Flatten(0)\n",
    "o1 = f1(output)\n",
    "\n",
    "o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = nn.Linear(5120, 64)\n",
    "o2 = l1(o1)\n",
    "\n",
    "o2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = nn.Linear(64, 1)\n",
    "o3 = l2(o2)\n",
    "\n",
    "o3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.8523e-01],\n",
      "        [ 4.5005e-01],\n",
      "        [ 1.5834e-01],\n",
      "        [-9.8807e-01],\n",
      "        [-2.0539e-01],\n",
      "        [ 1.0252e+00],\n",
      "        [-3.6740e-01],\n",
      "        [-1.2244e+00],\n",
      "        [-2.3265e-02],\n",
      "        [-1.5839e+00],\n",
      "        [ 6.4034e-01],\n",
      "        [-1.9665e+00],\n",
      "        [ 1.7263e+00],\n",
      "        [-3.7292e-01],\n",
      "        [ 1.6391e+00],\n",
      "        [-3.6448e-01],\n",
      "        [-5.6928e-02],\n",
      "        [ 3.9751e-01],\n",
      "        [-8.9022e-02],\n",
      "        [-1.2072e+00],\n",
      "        [-1.5513e+00],\n",
      "        [ 1.7884e+00],\n",
      "        [ 8.3717e-01],\n",
      "        [ 2.5921e-01],\n",
      "        [ 3.7565e-01],\n",
      "        [ 4.5042e-01],\n",
      "        [ 1.2479e-01],\n",
      "        [-3.2192e-01],\n",
      "        [-1.5225e+00],\n",
      "        [-5.8179e-01],\n",
      "        [ 4.1697e-01],\n",
      "        [-2.8003e-04]])\n"
     ]
    }
   ],
   "source": [
    "di = torch.randn(32,1)\n",
    "di_squeezed = di.squeeze()\n",
    "\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.8523e-01,  4.5005e-01,  1.5834e-01, -9.8807e-01, -2.0539e-01,\n",
      "         1.0252e+00, -3.6740e-01, -1.2244e+00, -2.3265e-02, -1.5839e+00,\n",
      "         6.4034e-01, -1.9665e+00,  1.7263e+00, -3.7292e-01,  1.6391e+00,\n",
      "        -3.6448e-01, -5.6928e-02,  3.9751e-01, -8.9022e-02, -1.2072e+00,\n",
      "        -1.5513e+00,  1.7884e+00,  8.3717e-01,  2.5921e-01,  3.7565e-01,\n",
      "         4.5042e-01,  1.2479e-01, -3.2192e-01, -1.5225e+00, -5.8179e-01,\n",
      "         4.1697e-01, -2.8003e-04])\n"
     ]
    }
   ],
   "source": [
    "print(di_squeezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 320, 32])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(17,32,320)\n",
    "x_permuted = x.permute(0, 2, 1)\n",
    "\n",
    "x_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2560])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from src.utils import *\n",
    "from src.model import LA_WKN_BiGRU\n",
    "\n",
    "pth_path = '/Users/yentsokuo/git_repo/WKN_SSO/src/your_model.pth'\n",
    "# 加载已经训练好的模型\n",
    "model = LA_WKN_BiGRU()  # 请替换为你的模型类\n",
    "model.load_state_dict(torch.load(pth_path))\n",
    "model.eval()  # 切换模型为评估模式\n",
    "\n",
    "# 准备输入数据（震动数据），这里使用示例数据，你需要根据你的数据结构进行调整\n",
    "input_path = '/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set/Bearing1_3/acc_00001.csv'  # 一个(1, 2560)尺寸的震动数据\n",
    "input_data = pd.read_csv(input_path, header=None, names=['hour', 'minute', 'second', 'microsecond', 'horiz accel', 'vert accel'])\n",
    "inputs = input_data['horiz accel'].values.astype(float)\n",
    "inputs = min_max_scale(inputs).reshape(1, -1)\n",
    "inputs_tensor = torch.from_numpy(inputs.astype(np.float32))\n",
    "# input_tensor = torch.Tensor(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2560])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "/Users/yentsokuo/git_repo/WKN_SSO/try/../src/model.py:41: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1009.)\n",
      "  return F.conv1d(waveforms, self.filters, stride=1, padding='same', dilation=1, bias=None, groups=1)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (320x16 and 5120x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/yentsokuo/git_repo/WKN_SSO/try/model.ipynb 儲存格 20\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yentsokuo/git_repo/WKN_SSO/try/model.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#使用模型进行预测\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yentsokuo/git_repo/WKN_SSO/try/model.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yentsokuo/git_repo/WKN_SSO/try/model.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     predicted_remaining_life \u001b[39m=\u001b[39m model(inputs_tensor)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yentsokuo/git_repo/WKN_SSO/try/model.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# 处理预测结果，这取决于你的任务\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yentsokuo/git_repo/WKN_SSO/try/model.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# 在这个例子中，predicted_remaining_life是一个float，表示预测的剩余寿命\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yentsokuo/git_repo/WKN_SSO/try/model.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredicted Remaining Life: \u001b[39m\u001b[39m{\u001b[39;00mpredicted_remaining_life\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git_repo/WKN_SSO/try/../src/model.py:75\u001b[0m, in \u001b[0;36mLA_WKN_BiGRU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m x,_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mBiGRU(x)\n\u001b[1;32m     74\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFC(x)\n\u001b[1;32m     76\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (320x16 and 5120x64)"
     ]
    }
   ],
   "source": [
    "#使用模型进行预测\n",
    "with torch.no_grad():\n",
    "    predicted_remaining_life = model(inputs_tensor)\n",
    "\n",
    "# 处理预测结果，这取决于你的任务\n",
    "# 在这个例子中，predicted_remaining_life是一个float，表示预测的剩余寿命\n",
    "print(f'Predicted Remaining Life: {predicted_remaining_life.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2560])\n",
      "torch.Size([1, 2560])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from math import pi\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def Morlet(p):\n",
    "    C = pow(pi, 0.25)\n",
    "    # p = 0.03 * p\n",
    "    y = C * torch.exp(-torch.pow(p, 2) / 2) * torch.cos(2 * pi * p)\n",
    "    return y\n",
    "\n",
    "a = np.random.rand(1, 2560)\n",
    "a = torch.from_numpy(a.astype(np.float32))\n",
    "print(a.shape)\n",
    "\n",
    "c = Morlet(a)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2560])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Morlet_fast(nn.Module):\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, in_channels=1):\n",
    "        super(Morlet_fast, self).__init__()\n",
    "        if in_channels != 1:\n",
    "            msg = \"MexhConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size - 1\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size = self.kernel_size + 1\n",
    "\n",
    "        self.a_ = nn.Parameter(torch.linspace(1, 10, out_channels)).view(-1, 1)\n",
    "        self.b_ = nn.Parameter(torch.linspace(0, 10, out_channels)).view(-1, 1)\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "        time_disc_right = torch.linspace(0, (self.kernel_size / 2) - 1,\n",
    "                                         steps=int((self.kernel_size / 2)))\n",
    "        time_disc_left = torch.linspace(-(self.kernel_size / 2) + 1, -1,\n",
    "                                        steps=int((self.kernel_size / 2)))\n",
    "        p1 = time_disc_right.cuda() - self.b_.cuda() / self.a_.cuda()\n",
    "        p2 = time_disc_left.cuda() - self.b_.cuda() / self.a_.cuda()\n",
    "\n",
    "        Morlet_right = Morlet(p1)\n",
    "        Morlet_left = Morlet(p2)\n",
    "\n",
    "        Morlet_filter = torch.cat([Morlet_left, Morlet_right], dim=1)  # 40x1x250\n",
    "        self.filters = (Morlet_filter).view(self.out_channels, 1, self.kernel_size).cuda()\n",
    "\n",
    "        return F.conv1d(waveforms, self.filters, stride=1, padding=1, dilation=1, bias=None, groups=1)\n",
    "    \n",
    "input = torch.randn(1, 2560).cuda()\n",
    "\n",
    "Morlat = Morlet_fast(32,64)\n",
    "Morlet_input = WKN(input)\n",
    "Morlet_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2560])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Laplace(p, A=0.08, ep=0.03, tal=0.1, f=50):\n",
    "    w = 2 * pi * f\n",
    "    q = torch.tensor(1 - pow(ep, 2))\n",
    "    \n",
    "    y = A * torch.exp((-ep / (torch.sqrt(q))) * (w * (p - tal))) * (-torch.sin(w * (p - tal)))\n",
    "    return y\n",
    "\n",
    "class Laplace_fast(nn.Module):\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, in_channels=1):\n",
    "        super(Laplace_fast, self).__init__()\n",
    "        if in_channels != 1:\n",
    "            msg = \"MexhConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size - 1\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size = self.kernel_size + 1\n",
    "\n",
    "        self.a_ = nn.Parameter(torch.linspace(1, 10, out_channels)).view(-1, 1)\n",
    "        self.b_ = nn.Parameter(torch.linspace(0, 10, out_channels)).view(-1, 1)\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "        time_disc = torch.linspace(0, 1, steps=int((self.kernel_size)))\n",
    "        p1 = time_disc.unsqueeze(0).cuda() - self.b_.cuda()/ self.a_.cuda()\n",
    "        laplace_filter = Laplace(p1, A = 0.08, ep = 0.03, tal = 0.1, f = 50)\n",
    "        self.filters = (laplace_filter).view(self.out_channels, 1, self.kernel_size).cuda()\n",
    "        # print(waveforms.shape)\n",
    "        # waveforms = waveforms.squeeze()\n",
    "        return F.conv1d(waveforms, self.filters, stride=1, padding='same', dilation=1, bias=None, groups=1)\n",
    "    \n",
    "input = torch.randn(1, 2560).cuda()\n",
    "\n",
    "LA = Laplace_fast(32,64)\n",
    "LA_input = LA(input)\n",
    "LA_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
