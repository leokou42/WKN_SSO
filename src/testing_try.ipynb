{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n",
      "torch.Size([32, 1, 2560])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 2560] at entry 0 and [1, 600] at entry 29",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\git_repo\\WKN_SSO\\src\\testing_try.ipynb 儲存格 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/git_repo/WKN_SSO/src/testing_try.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m model\u001b[39m.\u001b[39meval()  \u001b[39m# 切换模型为评估模式\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/git_repo/WKN_SSO/src/testing_try.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/git_repo/WKN_SSO/src/testing_try.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m data \u001b[39min\u001b[39;49;00m test_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/git_repo/WKN_SSO/src/testing_try.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         inputs \u001b[39m=\u001b[39;49m data[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/git_repo/WKN_SSO/src/testing_try.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39m# check if data size = 2560, if not, pop\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 2560] at entry 0 and [1, 600] at entry 29"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset_loader import CustomDataSet\n",
    "from model import LA_WKN_BiGRU\n",
    "\n",
    "work_condition = 1\n",
    "batch_size = 32\n",
    "\n",
    "Test_set = 'F:/git_repo/WKN_SSO/viberation_dataset/Test_set/'\n",
    "# Test_set = \"/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set/\"\n",
    "test_data = CustomDataSet(Test_set, work_condition, mode='test')\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "model = LA_WKN_BiGRU()  # 请替换为你的模型类\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LA_WKN_BiGRU().to(device)\n",
    "model.load_state_dict(torch.load('your_model.pth'))  # 请替换为你的模型.pth文件的路径\n",
    "model.eval()  # 切换模型为评估模式\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs = data[0].to(device)\n",
    "        # check if data size = 2560, if not, pop\n",
    "        if data.size() != torch.Size([32, 1, 2560]):\n",
    "            continue\n",
    "        print(data)\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import CustomDataSet\n",
    "from model import LA_WKN_BiGRU\n",
    "from utils import *\n",
    "\n",
    "model = LA_WKN_BiGRU()\n",
    "model.load_state_dict(torch.load('your_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_input = np.random.randn(1,2560)\n",
    "rnd_input = min_max_scale(rnd_input)\n",
    "rnd_input = torch.from_numpy(rnd_input.astype(np.float32))\n",
    "\n",
    "print(rnd_input.shape)\n",
    "predicted_remaining_life = model(rnd_input)\n",
    "\n",
    "print(f'Predicted Remaining Life: {predicted_remaining_life.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = '/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set'\n",
    "wc = 1\n",
    "test_data = CustomDataSet(testing_set, wc)\n",
    "test_loader = DataLoader(test_data)\n",
    "\n",
    "for data, labels in test_loader:\n",
    "    print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.Tensor(input_data)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_remaining_life = model(input_tensor)\n",
    "\n",
    "print(f'Predicted Remaining Life: {predicted_remaining_life.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tefuc(a, b, mode):\n",
    "    if mode == 'train':\n",
    "        return a\n",
    "    elif mode == 'test':\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = tefuc('a' , 'b', 'test')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def count_rows_in_csv(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # 讀取 CSV 檔案\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            \n",
    "            # 取得行數\n",
    "            row_count = len(df)\n",
    "            \n",
    "            if row_count == 2560:\n",
    "                pass\n",
    "                # print(\"File: {}\".format(file_path))\n",
    "            else:\n",
    "                print(\"File: {}, Rows: {}\".format(file_path,row_count))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# 指定你的資料夾路徑\n",
    "folder_path = '/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set/Bearing1_3'\n",
    "\n",
    "# 呼叫函數\n",
    "count_rows_in_csv(folder_path)\n",
    "print(\"done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
