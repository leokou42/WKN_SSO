{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset_loader import CustomDataSet\n",
    "from model import LA_WKN_BiGRU\n",
    "\n",
    "work_condition = 1\n",
    "batch_size = 32\n",
    "\n",
    "Test_set = 'F:/git_repo/WKN_SSO/viberation_dataset/Test_set/'\n",
    "# Test_set = \"/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set/\"\n",
    "test_data = CustomDataSet(Test_set, work_condition, mode='test')\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "model = LA_WKN_BiGRU()  # 请替换为你的模型类\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LA_WKN_BiGRU().to(device)\n",
    "model.load_state_dict(torch.load('your_model.pth'))  # 请替换为你的模型.pth文件的路径\n",
    "model.eval()  # 切换模型为评估模式\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs = data[0].to(device)\n",
    "        # check if data size = 2560, if not, pop\n",
    "        if data.size() != torch.Size([32, 1, 2560]):\n",
    "            continue\n",
    "        print(data)\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import CustomDataSet\n",
    "from model import LA_WKN_BiGRU\n",
    "from utils import *\n",
    "\n",
    "model = LA_WKN_BiGRU()\n",
    "model.load_state_dict(torch.load('your_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_input = np.random.randn(1,2560)\n",
    "rnd_input = min_max_scale(rnd_input)\n",
    "rnd_input = torch.from_numpy(rnd_input.astype(np.float32))\n",
    "\n",
    "print(rnd_input.shape)\n",
    "predicted_remaining_life = model(rnd_input)\n",
    "\n",
    "print(f'Predicted Remaining Life: {predicted_remaining_life.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = '/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set'\n",
    "wc = 1\n",
    "test_data = CustomDataSet(testing_set, wc)\n",
    "test_loader = DataLoader(test_data)\n",
    "\n",
    "for data, labels in test_loader:\n",
    "    print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.Tensor(input_data)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_remaining_life = model(input_tensor)\n",
    "\n",
    "print(f'Predicted Remaining Life: {predicted_remaining_life.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tefuc(a, b, mode):\n",
    "    if mode == 'train':\n",
    "        return a\n",
    "    elif mode == 'test':\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = tefuc('a' , 'b', 'test')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def count_rows_in_csv(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # 讀取 CSV 檔案\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            \n",
    "            # 取得行數\n",
    "            row_count = len(df)\n",
    "            \n",
    "            if row_count == 2560:\n",
    "                pass\n",
    "                # print(\"File: {}\".format(file_path))\n",
    "            else:\n",
    "                print(\"File: {}, Rows: {}\".format(file_path,row_count))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# 指定你的資料夾路徑\n",
    "folder_path = '/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set/Bearing1_3'\n",
    "\n",
    "# 呼叫函數\n",
    "count_rows_in_csv(folder_path)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "file1 = '/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set/Bearing1_4/acc_01139.csv'\n",
    "file2 = '/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set/Bearing1_4/temp_00001.csv'\n",
    "\n",
    "f1 = check_full_data(file1)\n",
    "f2 = check_full_data(file2)\n",
    "\n",
    "print(\"file1 is {}, file2 is {}\".format(f1, f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Test_set/Bearing1_7'\n",
    "work_condition = 1\n",
    "file_path = []\n",
    "wc = 'Bearing'\n",
    "wc = wc + str(work_condition)\n",
    "\n",
    "c=0\n",
    "for files in os.listdir(root_dir):\n",
    "    if files.endswith('.csv'):\n",
    "        path = os.path.join(root_dir, files)\n",
    "        path = os.path.normpath(path)\n",
    "        full = check_full_data(path)\n",
    "        if full:\n",
    "            file_path.append(path)\n",
    "\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([0.3998, 0.4485, 0.2712, 0.1878, 0.1446, 0.0863, 0.2053, 0.1519, 0.0755,\n",
    "#         0.1702, 0.1287, 0.1066, 0.1160, 0.0705, 0.1018, 0.1555, 0.1689, 0.1638,\n",
    "#         0.3471, 0.2113, 0.3736, 0.3620, 0.4069, 0.3740, 0.4477, 0.3586, 0.3707,\n",
    "#         0.3914, 0.3194, 0.3759, 0.3546, 0.3307], device='cuda:0')\n",
    "# size: torch.Size([19])\n",
    "# tensor([0.4809, 0.4917, 0.5051, 0.4504, 0.4787, 0.4743, 0.4205, 0.4822, 0.5496,\n",
    "#         0.4534, 0.4742, 0.3526, 0.2771, 0.2869, 0.4478, 0.5958, 0.3061, 0.4563,\n",
    "#         0.5040], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.randn(32)\n",
    "input2 = torch.randn(32)\n",
    "input3 = torch.randn(10)\n",
    "\n",
    "s = input1.size()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s == torch.Size([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val1 = input1.tolist()\n",
    "type(val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 1.1105, -0.7077, -1.1141,  1.1590, -1.3130, -0.6327, -0.3028,  0.1422,\n",
       "          0.8901,  2.5421, -1.7366,  0.4122,  0.8687,  1.6313,  1.1119, -1.1170,\n",
       "          0.2145, -0.4108,  0.2041,  0.4355,  1.7658, -0.5047,  0.5288,  0.8238,\n",
       "         -1.0623, -0.3077, -1.7248,  2.3880,  0.7674,  0.9270, -1.5932, -0.6276]),\n",
       " tensor([ 0.0425, -0.5647,  0.2471,  2.2562, -0.7736, -0.9029,  0.2505,  1.1557,\n",
       "          1.1542,  0.3517,  1.8423, -1.3527,  0.4443,  0.6867,  0.6979, -2.1972,\n",
       "          1.5808, -0.1194,  0.3383,  1.7181,  0.6177,  1.2742,  1.3476,  1.6420,\n",
       "         -0.6325, -0.2150, -0.7152,  0.8843,  0.0074, -0.8066, -0.9381,  0.8445]),\n",
       " tensor([ 1.0532, -0.0898, -1.8274,  0.0601, -0.1940, -0.5492,  0.1076, -1.0339,\n",
       "         -0.3436, -0.2493])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [input1,input2,input3]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "val = []\n",
    "for input in inputs:\n",
    "    tmp = input.tolist()\n",
    "    val.append(tmp)\n",
    "\n",
    "print(len(val))\n",
    "print(len(val[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yentsokuo/git_repo/WKN_SSO/src/testing_try.ipynb 儲存格 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yentsokuo/git_repo/WKN_SSO/src/testing_try.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m onedval \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(val)\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yentsokuo/git_repo/WKN_SSO/src/testing_try.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m onedval\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "onedval = np.array(val).flatten().tolist()\n",
    "onedval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onedval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Learning_set/Bearing1_1/acc_01188.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "root_dir = \"/Users/yentsokuo/git_repo/WKN_SSO/viberation_dataset/Learning_set\"\n",
    "work_condition = 1\n",
    "file_paths = []\n",
    "wk = 'Bearing'\n",
    "wk = wk + str(work_condition)\n",
    "for folder in os.listdir(root_dir):\n",
    "    if wk in folder:\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.endswith('.csv'):\n",
    "                    pathes = os.path.join(folder_path, filename)\n",
    "                    pathes = os.path.normpath(pathes)\n",
    "                    file_paths.append(pathes)\n",
    "\n",
    "label = get_health_index(root_dir, file_paths[3])\n",
    "file_paths[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947180585296217"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bearing1_3.png'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_set = 'F:/git_repo/WKN_SSO/viberation_dataset/Test_set/Bearing1_3'\n",
    "Bearing_name = Test_set.split('/')[-1]\n",
    "# Bearing_name\n",
    "pic_name = Bearing_name + '.png'\n",
    "pic_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 320])\n",
      "torch.Size([320, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "testi = torch.rand(32, 32, 320)\n",
    "print(testi.size())\n",
    "testi = testi.permute(2, 0, 1)\n",
    "print(testi.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 32, 16])\n",
      "torch.Size([32, 320, 16])\n",
      "torch.Size([32, 5120])\n",
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "bigru = nn.GRU(input_size=32, hidden_size=8, bidirectional=True)\n",
    "msa = nn.MultiheadAttention(embed_dim=16, num_heads=4)\n",
    "l0 = nn.Linear(5120, 64)\n",
    "f = nn.Flatten()\n",
    "l1 = nn.Linear(5120, 64)\n",
    "\n",
    "testo1,_ = bigru(testi)\n",
    "print(testo1.size())\n",
    "testo1 = testo1.transpose(0, 1)\n",
    "\n",
    "testo2,_ = msa(testo1,testo1,testo1)\n",
    "# testo2 = testo2.permute(1, 0, 2)\n",
    "print(testo2.size())\n",
    "\n",
    "testo3 = f(testo1)\n",
    "print(testo3.size())\n",
    "\n",
    "testo4 = l1(testo3)\n",
    "print(testo4.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
